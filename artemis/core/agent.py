"""
ARTEMIS Agent

Debate agent with H-L-DAG argument generation capabilities.
Agents generate structured arguments at strategic, tactical, and operational levels.
"""

from typing import Any

from artemis.core.argument import ArgumentParser
from artemis.core.prompts.hdag import (
    build_closing_prompt,
    build_generation_prompt,
    build_opening_prompt,
    build_rebuttal_prompt,
)
from artemis.core.types import (
    Argument,
    ArgumentLevel,
    DebateContext,
    Message,
    ReasoningConfig,
)
from artemis.exceptions import ArgumentGenerationError
from artemis.models import BaseModel, create_model
from artemis.utils.logging import get_logger

logger = get_logger(__name__)


class Agent:
    """
    Debate agent with H-L-DAG argument generation.

    Agents are participants in a debate, each with a defined role and position.
    They generate arguments following the Hierarchical Argument Generation
    framework at strategic, tactical, and operational levels.

    Example:
        >>> agent = Agent(
        ...     name="Proponent",
        ...     role="Argues in favor of the proposition",
        ...     model="gpt-4o",
        ... )
        >>> argument = await agent.generate_argument(context, ArgumentLevel.TACTICAL)
    """

    def __init__(
        self,
        name: str,
        role: str,
        model: str | BaseModel,
        position: str | None = None,
        persona: str | None = None,
        reasoning: ReasoningConfig | None = None,
        api_key: str | None = None,
        **model_kwargs: Any,
    ) -> None:
        """
        Initialize a debate agent.

        Args:
            name: Unique name for the agent.
            role: Description of the agent's role in the debate.
            model: Model identifier string or BaseModel instance.
            position: The agent's position on the debate topic.
            persona: Optional persona description for more nuanced arguments.
            reasoning: Configuration for extended thinking (for o1/R1 models).
            api_key: Optional API key for the model provider.
            **model_kwargs: Additional arguments passed to the model.
        """
        self.name = name
        self.role = role
        self.position = position
        self.persona = persona
        self.reasoning = reasoning or ReasoningConfig(enabled=False)

        # Initialize the model
        if isinstance(model, BaseModel):
            self._model = model
        else:
            self._model = create_model(model, api_key=api_key, **model_kwargs)

        # Argument parser for extracting structure
        self._parser = ArgumentParser()

        # Track generated arguments
        self._argument_history: list[Argument] = []

        logger.debug(
            "Agent initialized",
            name=name,
            role=role,
            model=self._model.model,
            reasoning_enabled=self.reasoning.enabled,
        )

    @property
    def model(self) -> BaseModel:
        """Get the underlying model."""
        return self._model

    @property
    def argument_history(self) -> list[Argument]:
        """Get the history of arguments generated by this agent."""
        return self._argument_history.copy()

    async def generate_argument(
        self,
        context: DebateContext,
        level: ArgumentLevel = ArgumentLevel.TACTICAL,
        additional_instructions: str | None = None,
    ) -> Argument:
        """
        Generate an argument at the specified hierarchical level.

        Args:
            context: Current debate context including topic and transcript.
            level: The H-L-DAG level (strategic, tactical, operational).
            additional_instructions: Optional extra instructions for generation.

        Returns:
            Generated Argument object.

        Raises:
            ArgumentGenerationError: If argument generation fails.
        """
        logger.info(
            "Generating argument",
            agent=self.name,
            level=level.value,
            round=context.current_round,
        )

        try:
            # Build prompts
            system_prompt, user_prompt = build_generation_prompt(
                context=context,
                agent_name=self.name,
                role=self.role,
                level=level,
                persona=self.persona,
                additional_instructions=additional_instructions,
            )

            # Generate response
            messages = [
                Message(role="system", content=system_prompt),
                Message(role="user", content=user_prompt),
            ]

            thinking_trace: str | None = None
            content: str

            if self.reasoning.enabled and self._model.supports_reasoning:
                reasoning_response = await self._model.generate_with_reasoning(
                    messages=messages,
                    thinking_budget=self.reasoning.thinking_budget,
                )
                content = reasoning_response.content
                thinking_trace = reasoning_response.thinking
            else:
                response = await self._model.generate(messages=messages)
                content = response.content

            # Parse the response into structured argument
            argument = self._parser.parse(
                content=content,
                agent=self.name,
                level=level,
            )

            # Add thinking trace if available
            if thinking_trace and self.reasoning.include_trace_in_output:
                argument = Argument(
                    id=argument.id,
                    agent=argument.agent,
                    level=argument.level,
                    content=argument.content,
                    evidence=argument.evidence,
                    causal_links=argument.causal_links,
                    rebuts=argument.rebuts,
                    supports=argument.supports,
                    ethical_score=argument.ethical_score,
                    thinking_trace=thinking_trace,
                    timestamp=argument.timestamp,
                )

            # Track in history
            self._argument_history.append(argument)

            logger.info(
                "Argument generated",
                agent=self.name,
                argument_id=argument.id,
                level=level.value,
                evidence_count=len(argument.evidence),
                causal_links_count=len(argument.causal_links),
            )

            return argument

        except Exception as e:
            logger.error(
                "Argument generation failed",
                agent=self.name,
                level=level.value,
                error=str(e),
            )
            raise ArgumentGenerationError(
                message=f"Failed to generate {level.value} argument: {e}",
                agent_name=self.name,
            ) from e

    async def generate_opening(self, context: DebateContext) -> Argument:
        """
        Generate an opening statement.

        Args:
            context: Current debate context.

        Returns:
            Opening statement as a strategic-level Argument.
        """
        logger.info("Generating opening statement", agent=self.name)

        try:
            system_prompt, user_prompt = build_opening_prompt(
                context=context,
                agent_name=self.name,
                role=self.role,
                persona=self.persona,
            )

            messages = [
                Message(role="system", content=system_prompt),
                Message(role="user", content=user_prompt),
            ]

            response = await self._model.generate(messages=messages)

            argument = self._parser.parse(
                content=response.content,
                agent=self.name,
                level=ArgumentLevel.STRATEGIC,
            )

            self._argument_history.append(argument)
            return argument

        except Exception as e:
            raise ArgumentGenerationError(
                message=f"Failed to generate opening statement: {e}",
                agent_name=self.name,
            ) from e

    async def generate_closing(self, context: DebateContext) -> Argument:
        """
        Generate a closing statement.

        Args:
            context: Current debate context with full transcript.

        Returns:
            Closing statement as a strategic-level Argument.
        """
        logger.info("Generating closing statement", agent=self.name)

        try:
            system_prompt, user_prompt = build_closing_prompt(
                context=context,
                agent_name=self.name,
                role=self.role,
                persona=self.persona,
            )

            messages = [
                Message(role="system", content=system_prompt),
                Message(role="user", content=user_prompt),
            ]

            response = await self._model.generate(messages=messages)

            argument = self._parser.parse(
                content=response.content,
                agent=self.name,
                level=ArgumentLevel.STRATEGIC,
            )

            self._argument_history.append(argument)
            return argument

        except Exception as e:
            raise ArgumentGenerationError(
                message=f"Failed to generate closing statement: {e}",
                agent_name=self.name,
            ) from e

    async def generate_rebuttal(
        self,
        context: DebateContext,
        target_argument: Argument,
        level: ArgumentLevel = ArgumentLevel.TACTICAL,
    ) -> Argument:
        """
        Generate a rebuttal to a specific argument.

        Args:
            context: Current debate context.
            target_argument: The argument to rebut.
            level: The hierarchical level for the rebuttal.

        Returns:
            Rebuttal Argument linked to the target.
        """
        logger.info(
            "Generating rebuttal",
            agent=self.name,
            target_id=target_argument.id,
            target_agent=target_argument.agent,
        )

        try:
            system_prompt, user_prompt = build_rebuttal_prompt(
                context=context,
                agent_name=self.name,
                role=self.role,
                target_argument=target_argument.content,
                level=level,
                persona=self.persona,
            )

            messages = [
                Message(role="system", content=system_prompt),
                Message(role="user", content=user_prompt),
            ]

            response = await self._model.generate(messages=messages)

            # Parse and link to target
            argument = self._parser.parse(
                content=response.content,
                agent=self.name,
                level=level,
            )

            # Create new argument with rebuttal link
            argument = Argument(
                id=argument.id,
                agent=argument.agent,
                level=argument.level,
                content=argument.content,
                evidence=argument.evidence,
                causal_links=argument.causal_links,
                rebuts=target_argument.id,
                supports=argument.supports,
                ethical_score=argument.ethical_score,
                thinking_trace=argument.thinking_trace,
                timestamp=argument.timestamp,
            )

            self._argument_history.append(argument)
            return argument

        except Exception as e:
            raise ArgumentGenerationError(
                message=f"Failed to generate rebuttal: {e}",
                agent_name=self.name,
            ) from e

    def __repr__(self) -> str:
        return f"Agent(name={self.name!r}, role={self.role!r}, model={self._model.model!r})"
